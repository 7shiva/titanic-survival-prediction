Name: Shiva Thakur 
Project Name: Titanic Survival Prediction 
ABSTRACT: The sinking of the RMS Titanic caused the death of thousands of passengers and crew is  one  of  the  deadliest  maritime disasters in history. One of the reasons that the shipwreck led to such loss of life was that there were not  enough lifeboats for the  passengers  and  crew.  The interesting  observation which comes out from the  sinking is that some  people were more likely to survive than others, like women, children were the one who got the priority to rescue. The objective is to first explore hidden or previously  unknown  information  by applying exploratory data analytics on available  dataset and then apply different machine learning models to complete the analysis of what sorts of people were likely to survive. After this the results  of  applying  machine  learning  models  are compared and analyzed on the basis of accuracy.  ABOUT PROJECT: We deal with two datasets, training data and testing data. For the training set, all information for each passenger is given. Our main aim is to fill up the survival column of the test data set. A simple model is not always a bad model. Building a sophisticated model (by adding too many variables) might not improve the prediction accuracy of the model. A moderate model (not too simple and not too complex) is sufficient for developing a robust prediction system. 
I Use three Models: 
1. Logistic Regression: The first model that we are going to use is the logistic regression. It is a linear model widespread. Fast, easy to use and easy to understand this model must be part of your toolbox. The fact of being a linear model demands in general rules more preprocessing to have the best results. For our example we have kept just one dataset but keep in mind that a good practice is to work with one dataset for the linear models and another one for the non-linear model.
2. Random Forest: The second model is the Random Forest. For my part i prefer to use Extremely randomized trees which is better than the Random Forest in term of variance. In general rules the extreme version of an algorithm adds a layer of penalization or a random layer for a better generalization.
3. Support Vector Machine: Finally I would like to finish with the SVC (Support Vector Classification). The implementation is based on libsvm. The fit time complexity is more than quadratic with the number of samples which makes it hard to scale to dataset with more than a couple of 10000 samples. The multiclass support is handled according to a one-vs-one scheme. 
CONCLUSION: Data cleaning is the first step while performing data analysis. Exploratory data analytics helps one to understand the dataset and  the  dependency  among  the  attributes.  EDA  is used  to figure out the relationship between the features of the dataset. This is done  by using various  graphical techniques.  The one used above is ggplot and histograms.  By applying EDA some conclusions are drawn and facts  are found.  There is high influence of age  on survival. We can see from table-2 that as age increases survival decreases. It  can  be  seen  that  survival  rate  of  female  is  very  high (approx. 74%) and survival rate of male is very low. This fact can  also  be verified  by  extracting  titles  (Mr, Mrs,  Ms  etc) from  name  column.  Survival  rate  with  title  Mr.  is approximately 16% while survival rate for Mrs. is 79%. Comparison of three models are shown below.
COMPARISION OF PERFORMANCE Logistic Regression 0.828358 Random Forest 0.787313 SVM 0.787313 
 
 
 
